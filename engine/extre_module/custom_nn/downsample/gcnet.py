'''  
本文件由BiliBili：魔傀面具整理     
engine/extre_module/module_images/IEEETIP2020-ContextGuidedBlock_Down.png   
论文链接：https://arxiv.org/pdf/1811.08201
'''
     
import os, sys
sys.path.append(os.path.dirname(os.path.abspath(__file__)) + '/../../../..')
     
import warnings
warnings.filterwarnings('ignore')    
from calflops import calculate_flops     
   
import torch 
import torch.nn as nn    
from engine.extre_module.ultralytics_nn.conv import Conv, autopad 
    
class FGlo(nn.Module):
    """
    the FGlo class is employed to refine the joint feature of both local feature and surrounding context.    
    """     
    def __init__(self, channel, reduction=16):   
        super(FGlo, self).__init__()     
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        self.fc = nn.Sequential(
                nn.Linear(channel, channel // reduction),
                nn.ReLU(inplace=True),
                nn.Linear(channel // reduction, channel),
                nn.Sigmoid() 
        )
  
    def forward(self, x):
        b, c, _, _ = x.size()
        y = self.avg_pool(x).view(b, c)
        y = self.fc(y).view(b, c, 1, 1)
        return x * y

class ContextGuidedBlock(nn.Module): 
    def __init__(self, nIn, nOut, dilation_rate=2, reduction=16, add=True):
        """
        args:
           nIn: number of input channels  
           nOut: number of output channels, 
           add: if true, residual learning 
        """    
        super().__init__() 
        n= int(nOut/2) 
        self.conv1x1 = Conv(nIn, n, 1, 1)  #1x1 Conv is employed to reduce the computation
        self.F_loc = nn.Conv2d(n, n, 3, padding=1, groups=n)   
        self.F_sur = nn.Conv2d(n, n, 3, padding=autopad(3, None, dilation_rate), dilation=dilation_rate, groups=n) # surrounding context 
        self.bn_act = nn.Sequential(    
            nn.BatchNorm2d(nOut),    
            Conv.default_act
        )
        self.add = add  
        self.F_glo= FGlo(nOut, reduction)  
    
    def forward(self, input):
        output = self.conv1x1(input) 
        loc = self.F_loc(output)   
        sur = self.F_sur(output) 
        
        joi_feat = torch.cat([loc, sur], 1) 

        joi_feat = self.bn_act(joi_feat)   

        output = self.F_glo(joi_feat)  #F_glo is employed to refine the joint feature   
        # if residual version  
        if self.add:
            output  = input + output 
        return output  

class ContextGuidedBlock_Down(nn.Module):     
    """
    the size of feature map divided 2, (H,W,C)---->(H/2, W/2, 2C)
    """
    def __init__(self, nIn, nOut, dilation_rate=2, reduction=16):
        """
        args:
           nIn: the channel of input feature map     
           nOut: the channel of output feature map  
        """   
        super().__init__()  
        self.conv1x1 = Conv(nIn, nOut, 3, s=2)  #  size/2, channel: nIn--->nOut  
        
        self.F_loc = nn.Conv2d(nOut, nOut, 3, padding=1, groups=nOut)    
        self.F_sur = nn.Conv2d(nOut, nOut, 3, padding=autopad(3, None, dilation_rate), dilation=dilation_rate, groups=nOut) 
        
        self.bn = nn.BatchNorm2d(2 * nOut, eps=1e-3)
        self.act = Conv.default_act 
        self.reduce = Conv(2 * nOut, nOut,1,1)  #reduce dimension: 2*nOut--->nOut
     
        self.F_glo = FGlo(nOut, reduction)  
  
    def forward(self, input):
        print(1111111111111111)
        output = self.conv1x1(input)
        loc = self.F_loc(output)
        sur = self.F_sur(output)     

        joi_feat = torch.cat([loc, sur],1)  #  the joint feature
        joi_feat = self.bn(joi_feat)    
        joi_feat = self.act(joi_feat)
        joi_feat = self.reduce(joi_feat)     #channel= nOut 
        
        output = self.F_glo(joi_feat)  # F_glo is employed to refine the joint feature   

        return output
 
if __name__ == '__main__':
    RED, GREEN, BLUE, YELLOW, ORANGE, RESET = "\033[91m", "\033[92m", "\033[94m", "\033[93m", "\033[38;5;208m", "\033[0m"
    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')
    batch_size, in_channel, out_channel, height, width = 1, 16, 32, 32, 32    
    inputs = torch.randn((batch_size, in_channel, height, width)).to(device) 

    module = ContextGuidedBlock_Down(in_channel, out_channel).to(device)
   
    outputs = module(inputs)
    print(GREEN + f'inputs.size:{inputs.size()} outputs.size:{outputs.size()}' + RESET)

    print(ORANGE)    
    flops, macs, _ = calculate_flops(model=module,
                                     input_shape=(batch_size, in_channel, height, width),
                                     output_as_string=True,
                                     output_precision=4,  
                                     print_detailed=True)   
    print(RESET)
    
    # python tools/benchmark/get_info.py -c configs/test/deim_hgnetv2_n_visdrone.yml